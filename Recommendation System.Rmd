---
title: "Recommendation System"
author: "Akkash Kothapalli"
output:
  html_notebook: default
---

## Agenda

1. What is Recommendation System.
2. Types of Recommendation Systems
    * Traditional
    * Novel
3. Evaluation
    * RMSE/MAE
    * Precision Recall
4. Examples
5. Q&A


## What is a Recommender System?

Recommender systems are software tools that predicts which user might like which item or viceverse.

Best examples are Netflix , Amazon, Facebook, Google etc.

  * Bcoz nearly 35% of the revenue generated by Amazon are by Recommendation
  * 2/3 Movies that are watch recommended movies.
  
Recommendation drives revenue for the companies. The best example is Banking. 

#### Recommendations are used in
    News
    Tourism
    Music
    E-Commerce
    Movies
    Finance
    Job Search
    
    
## Types of Recommender Systems

  1. Traditional
  2. Novel
  
#### Traditional
    Popularity / Trending
    Collaborative Filtering
    Content Based
    Knowledge Based
    Association Rules
    

##### Collaborative Filtering

This is one of the most common and traditional algorithm. It is of 2 types
    
    1. User Based CF
    2. Item based CF

We will be creating the basic collaborative filtering from scratch. Later we will be creating using recommenderlab package.

```{r}
library(recommenderlab)
library(caret)
data("MovieLense")
```


Here we are binarizing the dataset. If the User has rated anything greater than 0 then its 

```{r}
movie.m <- as.data.frame(as.matrix(MovieLense@data))

#View(movie.m)

movie.m[movie.m > 0] <- 1

image(as.matrix(movie.m))
```

```{r}
head(movie.m)
```


Now we hae created the dataset. The basic idea behind a collaborative filtering is that its find the similarities between User-User or Item-Item. Here in this demo we will be using the User-User CF. 

But how to find similarity between User-user or Item-Item

There are different types of similairty formulas that can be used the most common are
  
    1. Cosine 
    2. Pearson Correlation
    3. Jaccard

```{r}
distance <- as.matrix(dist(movie.m,method = 'euclidean'))
#View(distance)

correlation <- as.matrix(dist(movie.m,method = 'correlation'))
#View(correlation)

jaccard <- as.matrix(dist(movie.m,method = 'jaccard'))
#View(jaccard)

cosine <- as.matrix(dist(movie.m,method = 'cosine'))
#View(cosine)
```

Now lets find the nearest neighbours

```{r}
k.nearest.neighbors <- function(i, recommender, k = 5)
{
  ordered.neighbors <- order(recommender[i, ])
  # This just gives us the list of points that are
  # closest to row i in descending order.
  
  # The first entry is always 0 (the closest point is the point itself) so 
  # let's ignore that entry and return points 2:(k+1) instead of 1:k
  return(ordered.neighbors[2:(k + 1)])
}
```


```{r}
cat('euclidian..')
k.nearest.neighbors(25,distance,15) #eculidian
cat('correlation..')
k.nearest.neighbors(25,correlation,15) #correlation
cat('jaccard..')
k.nearest.neighbors(25,jaccard,15) #jaccard
cat('cosine..')
k.nearest.neighbors(25,cosine,15) #cosine
```

Now lets find the probability of the user watching a particular movie

```{r}
seen.probability <- function(user, movie, recommender, distances, k = 25)
{
  # Find the kNN closest movies to this movie in question.
  
  neighbors <- k.nearest.neighbors(which(row.names(movie.m) == user), distances, k)
  
  # Now that we know the other movies that have been seen with this one, return
  # the mean of how many of those movies this user could see.
  return(mean(movie.m[neighbors, movie]))
}
```


```{r}
seen.probability(5,'Four Rooms (1995)',movie.m,distance)
seen.probability(5,'GoldenEye (1995)',movie.m,distance)
seen.probability(5,'Toy Story (1995)',movie.m,distance)
```

```{r}
most.prob.movies <- function(user,recommender,distance,k=25){
  probabilities <- rep(0,ncol(recommender))
  for(i in 1:ncol(recommender)){
    if(recommender[user,i]==1){
      next
    }
    probabilities[i] <- seen.probability(user,colnames(recommender)[i],recommender,distance,k)
  }
  return(order(probabilities,decreasing = T))
}
```


```{r}
user_movies <- movie.m[25,]
viewed_movies <- colnames(user_movies[,user_movies==1])

viewed_movies

cat('\n Movies to recommend \n \n')

listing <- most.prob.movies(25,movie.m,distance)
colnames(movie.m)[listing[1:10]]
```


```{r}
user_movies <- movie.m[65,]
viewed_movies <- colnames(user_movies[,user_movies==1])

viewed_movies

cat('\n Movies to recommend \n \n')

listing <- most.prob.movies(65,movie.m,distance)
colnames(movie.m)[listing[1:10]]
```


#### Content Based Learning

```{r}

cb.m <- MovieLenseMeta[,-c(2,3)]

summary(cb.m)
str(cb.m)
```

```{r}
cb.m[1,1]
#Birdcage, The (1996)

cb.m[,2:20] <- lapply(cb.m[,2:20],as.numeric)
```

```{r}
cb.dist <- as.matrix(dist(cb.m[,2:20],method = 'jaccard'))
# View(cb.dist)
```

```{r}
k.nearest.n <- function(i,distance,k=25){
  ordered.n <- order(distance[i,])
  return(ordered.n[ordered.n != i][1:5])
}
```

```{r}
#Toy Story
similar.content <- k.nearest.n(1,cb.dist,k=5)

cb.m[similar.content,1]
```

```{r}
#Goldeneye
similar.content <- k.nearest.n(2,cb.dist,k=5)

cb.m[similar.content,1]
```

```{r}
#Nightmare at elm street
similar.content <- k.nearest.n(219,cb.dist,k=5)

cb.m[similar.content,1]
```

#### Drawback in Traditional?

    Cold Start
    Sparsity
    Interdependency and complex behaviours
    
#### Assocition Rules - Market Basket Analysis

Its a set of rules that can understand *IF THIS, THEN THAT*

This is predominantly used in Amazon for product recommendation. *User who bought this have also bought this*.

```{r}
library(datasets)
library(arules)

data("Groceries")
```

```{r}
itemFrequencyPlot(Groceries,topN=20,type="absolute")
```

```{r}
groceryRules <- apriori(Groceries,parameter = list(support=0.001, confidence=0.8))
options(digits = 2)
inspect(groceryRules[1:5])
```

```{r}
rul <- sort(groceryRules, by="confidence", decreasinig=TRUE)
```


Targeting Items
```{r}
groceryRules <- apriori(Groceries,parameter = list(support=0.001, confidence=0.03), 
                        appearance = list(default="lhs",rhs='soda'))
rul <- sort(groceryRules, by="confidence", decreasinig=TRUE)
inspect(rul[1:5])
```

#### Matrix Factorization

In otehr words called as Decomposition. Dimensionality Reduction. THe reason we need DR is that ther are sparse data when it comes to recommendation system. Inorder to reduce the size and dimension we use DR.

Most commonly used DR algorithm is Singular Value Decomposition

```{r}

svdM <- svd(movie.m)
sigmaK <- svdM$d; Uk <- svdM$u; Vk <- svdM$v
```

```{r}
plot(sigmaK,pch=20, main="Singular value for User-Item Matrix")
```

```{r}
sigmaK[1:100]
```

```{r}
all_sq <- sum(sigmaK^2)
```

```{r}
vecc <- NULL

for(i in 1:length(sigmaK)){
  vecc[i] <- sum(sigmaK[1:i]^2) / all_sq
}
```

```{r}
plot(vecc, col="red")
lines(x=c(0,1000),y=c(.90,.90))
```

```{r}
length(vecc[vecc <= .90])
```

```{r}
# when k=286, we create a truncated svd

sigmaK2 <- Diagonal(x=sigmaK[1:286])
dim(sigmaK2)
Uk2 <- Uk[,1:286]
dim(Uk2)
Vk2 <- t(Vk[,1:286])
dim(Vk2)
```

```{r}
# Actual dimensions
1664*943

#SVD dimensions
(943*286)+(286*286)+(286*1664)

827398/1569152
```

```{r}
predicted <- Uk2 %*% sigmaK2 %*% Vk2
```

#### Using RecommenderLab 

Finding Similar User

```{r}
similarity_users <- similarity(MovieLense[1:4, ], method = "cosine", which = "users")

image(as.matrix(similarity_users), main = "User similarity")
```

Finding Similar Item

```{r}
similarity_items <- similarity(MovieLense[, 1:4], method = "cosine", which = "items")

image(as.matrix(similarity_items), main = "Item similarity")
```

DIfferent Models available in Recommnederlab

```{r}
recommender_models <- recommenderRegistry$get_entries(dataType = "realRatingMatrix")
recommender_models
```

Geting only the most relavent user and movies

```{r}
ratings_movies <- MovieLense[rowCounts(MovieLense) > 50,
                             colCounts(MovieLense) > 100]
ratings_movies_watched <- binarize(ratings_movies, minRating = 1)
```

```{r}
# visualize the top matrix
min_movies <- quantile(rowCounts(ratings_movies), 0.98)
min_users <- quantile(colCounts(ratings_movies), 0.98)
image(ratings_movies[rowCounts(ratings_movies) > min_movies,
                     colCounts(ratings_movies) > min_users],
      main = "Heatmap of the top users and movies")
```

Normalizing the Dataset

```{r}
ratings_movies_norm <- normalize(ratings_movies)
```

Creating a Train/Test Dataset

```{r}
which_train <- sample(x = c(TRUE, FALSE),
                      size = nrow(ratings_movies),
                      replace = TRUE,
                      prob = c(0.8, 0.2))
recc_data_train <- ratings_movies[which_train, ]
recc_data_test <- ratings_movies[!which_train, ]
```

Item based CF

```{r}
recc_model <- Recommender(data = recc_data_train,
                          method = "IBCF",
                          parameter = list(method = "Jaccard"))
model_details <- getModel(recc_model)
```


```{r}
n_recommended <- 6
recc_predicted <- predict(object = recc_model, 
                          newdata = recc_data_test,
                          n = n_recommended)
recc_matrix <- sapply(recc_predicted@items, function(x){
  colnames(ratings_movies)[x]
})
```

User Based CF

```{r}
recc_model <- Recommender(data = recc_data_train,
                          method = "UBCF",
                          parameter = list(method = "Jaccard"))
recc_model
```

```{r}
n_recommended <- 15
recc_predicted <- predict(object = recc_model, 
                          newdata = recc_data_test,
                          n = n_recommended)
recc_matrix <- sapply(recc_predicted@items, function(x){
  colnames(ratings_movies)[x]
})
dim(recc_matrix)
```

```{r}
recc_matrix[,1:2]
```

```{r}
user_movies <- movie.m[10,]
viewed_movies <- colnames(user_movies[,user_movies==1])

#viewed_movies

cat('\n Movies to recommend \n \n')

listing <- most.prob.movies(10,movie.m,distance)
colnames(movie.m)[listing[1:10]]
```


```{r}
recc_model <- Recommender(data = recc_data_train,
                          method = "SVD",
                          parameter = list(method = "Jaccard"))
recc_model
```

```{r}
n_fold <- 4
items_to_keep <- 15
rating_threshold <- 3
eval_sets <- evaluationScheme(data = ratings_movies, method = "split", train=0.8,
k = n_fold, given = items_to_keep, goodRating = rating_threshold)
```


```{r}
UBCF_N_C <- Recommender(getData(eval_sets, "train"), "UBCF", 
      param=list(normalize = NULL, method="Cosine"))

# centered
IBCF_Z_C <- Recommender(getData(eval_sets, "train"), "IBCF", 
      param=list(normalize = "Z-score",method="Cosine"))

```

  
  
```{r}
Jp1 <- predict(UBCF_N_C, getData(eval_sets, "known"), type="ratings")

Jp2 <- predict(IBCF_Z_C, getData(eval_sets, "known"), type="ratings")
```

```{r}
errors <- rbind(
  # jester data
  UBCF_N_C = calcPredictionAccuracy(Jp1, getData(eval_sets, "unknown")),
  IBCF_Z_C = calcPredictionAccuracy(Jp2, getData(eval_sets, "unknown"))
)
```

```{r}
errors
```



